{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4228433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Train Loss 0.2052\n",
      "Epoch 02 Train Loss 0.0848\n",
      "Epoch 03 Train Loss 0.0596\n",
      "Epoch 04 Train Loss 0.0469\n",
      "Epoch 05 Train Loss 0.0393\n",
      "Epoch 06 Train Loss 0.0314\n",
      "Epoch 07 Train Loss 0.0264\n",
      "Epoch 08 Train Loss 0.0263\n",
      "Epoch 09 Train Loss 0.0223\n",
      "Epoch 10 Train Loss 0.0220\n",
      "tensor([[1.1278e-21, 3.8479e-20, 3.8236e-21, 7.5338e-14, 5.8392e-19, 1.0000e+00,\n",
      "         7.9986e-17, 1.4481e-20, 6.7417e-15, 9.0448e-10]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "\n",
    "train_ds = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_ds = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=1000,shuffle=True)\n",
    "\n",
    "class Mymodule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(784,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        y = self.seq(x)\n",
    "        return y\n",
    "    \n",
    "model = Mymodule()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} Train Loss {total_loss/len(train_loader):.04f}\")\n",
    "\n",
    "img = Image.open('numberImage.png').convert('L')\n",
    "to_tensor = transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "\n",
    "model.eval()\n",
    "x = to_tensor(img).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    logits = model(x)\n",
    "    probs = nn .functional.softmax(logits, dim=1)\n",
    "\n",
    "print(probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
